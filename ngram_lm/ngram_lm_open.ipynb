{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "import lm_model as lm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sam', 0.1), ('ham', 0.2), ('<s>', 0.4), ('i', 0.6000000000000001), ('am', 0.8), ('</s>', 1.0)]\n",
      "[('sam', 0.1), ('ham', 0.2), ('<s>', 0.4), ('i', 0.6000000000000001), ('am', 0.8), ('</s>', 1.0)]\n",
      "['<s>', 'sam']\n",
      "['<s>', 'sam', 'sam']\n",
      "['<s>', 'sam', 'sam', 'ham']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am', 'am']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am', 'am', 'i']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am', 'am', 'i', 'i']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am', 'am', 'i', 'i', 'i']\n",
      "['<s>', 'sam', 'sam', 'ham', 'am', 'am', 'i', 'i', 'i', 'i']\n",
      "[['<s>', '</s>'], ['<s>', 'sam', 'sam', 'ham', 'am', 'am', 'i', 'i', 'i', 'i', '</s>']]\n",
      "[['<s>', 'ham', '</s>'], ['<s>', 'i', 'am', 'sam', '</s>']]\n",
      "[('<s>', 0.2), ('</s>', 0.4), ('<UNK>', 1.0)]\n",
      "['<s>']\n",
      "['<s>']\n",
      "['<s>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>']\n",
      "[('<s>', 0.2), ('</s>', 0.4), ('<UNK>', 1.0)]\n",
      "['<s>']\n",
      "['<s>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>']\n",
      "[('<s>', 0.2), ('</s>', 0.4), ('<UNK>', 1.0)]\n",
      "['<s>', '<UNK>']\n",
      "['<s>', '<UNK>']\n",
      "[('<s>', 0.2), ('</s>', 0.4), ('<UNK>', 1.0)]\n",
      "['<s>', '<UNK>']\n",
      "[('<s>', 0.2), ('</s>', 0.4), ('<UNK>', 1.0)]\n",
      "['<s>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>']\n",
      "sent ['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '</s>']\n",
      "sent ['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '</s>']\n",
      "sent ['<s>', '<UNK>', '<UNK>', '<UNK>', '</s>']\n",
      "sent ['<s>', '<UNK>', '</s>']\n",
      "sent ['<s>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', '</s>']\n"
     ]
    }
   ],
   "source": [
    "# test the language model (unit tests)\n",
    "import test_minitrainingprovided as test\n",
    "\n",
    "\n",
    "unittest = test.TestMiniTraining()\n",
    "unittest.test_createunigrammodellaplace()\n",
    "unittest.test_createbigrammodellaplace()\n",
    "unittest.test_unigramlaplace()\n",
    "unittest.test_unigramunknownslaplace()\n",
    "unittest.test_bigramlaplace()\n",
    "unittest.test_bigramunknownslaplace()\n",
    "# produces output\n",
    "unittest.test_generateunigramconcludes()\n",
    "# produces output\n",
    "unittest.test_generatebigramconcludes()\n",
    "\n",
    "unittest.test_onlyunknownsgenerationandscoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'i', 'would', 'like', 'to', 'eat', 'on', 'wednesday', '</s>']\n",
      "['<s>', 'i', 'would', 'like', 'information', 'about', 'fifteen', 'minutes', 'from', 'icsi', '</s>']\n",
      "['<s>', 'lunch', '</s>']\n",
      "['<s>', \"i'd\", 'like', 'french', 'restaurant', '</s>']\n",
      "['<s>', 'what', 'about', 'sixty', 'dollars', '</s>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# instantiate a bigram language model, train it, and generate ten sentences\n",
    "# make sure your output is nicely formatted!\n",
    "ngram = 2\n",
    "training_file_path = \"training_files/berp-training.txt\"\n",
    "# optional parameter tells the tokenize function how to tokenize\n",
    "by_char = False\n",
    "data = lm.read_file(training_file_path)\n",
    "tokens = lm.tokenize(data, ngram, by_char=by_char)\n",
    "\n",
    "l=lm.LanguageModel(ngram)\n",
    "l.train(tokens)\n",
    "sen=l.generate(5)\n",
    "for s in sen:\n",
    "    print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram1 = 2\n",
    "training_file_path1 = \"training_files/berp-training.txt\"\n",
    "# optional parameter tells the tokenize function how to tokenize\n",
    "by_char = False\n",
    "data1 = lm.read_file(training_file_path1)\n",
    "tokens1 = lm.tokenize(data1, ngram1, by_char=by_char)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'at', 'the', 'icsi', '</s>']\n",
      "['<s>', 'i', 'would', 'like', '</s>']\n",
      "['<s>', 'show', 'me', 'the', 'restaurant', '</s>']\n",
      "['<s>', 'where', 'i', 'would', 'like', 'to', 'eat', 'tomorrow', '</s>']\n",
      "['<s>', 'what', 'time', 'so', 'now', \"i'm\", 'willing', 'to', 'go', 'there', 'other', 'italian', 'restaurant', '</s>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lt=lm.LanguageModel(ngram1)\n",
    "lt.train(tokens1)\n",
    "sen=lt.generate(5)\n",
    "for s in sen:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6911851372734653e-08, 7.130904665204505e-05, 1.232898920510186e-06, 4.597871457327673e-10, 6.780174701924407e-24]\n",
      "mean 1.4511863442214742e-05\n",
      "std 2.840256874850023e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_path = \"testing_files/berp-test.txt\"\n",
    "test_data = lm.read_file(test_path)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for s in sen:\n",
    "    scores.append(l.score(s))\n",
    "print(scores)\n",
    "scores = np.array(scores)\n",
    "print('mean',scores.mean())\n",
    "print('std',scores.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', 'i', 'want', 'american', 'food', '</s>']\n",
      "['<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', 'start', 'over', '</s>']\n",
      "['<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', '<s>', 'i', 'want', 'to', 'eat', 'some', 'german', 'food', 'please', '</s>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_my(n):\n",
    "    ngram = n\n",
    "    training_file_path = \"training_files\\my_training.txt\"\n",
    "    # optional parameter tells the tokenize function how to tokenize\n",
    "    by_char = False\n",
    "    data = lm.read_file(training_file_path)\n",
    "    tokens = lm.tokenize(data, ngram, by_char=by_char)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    l=lm.LanguageModel(ngram)\n",
    "    l.train(tokens)\n",
    "    return l\n",
    "\n",
    "\n",
    "\n",
    "# generate three sentences with this model\n",
    "for i in train_my(10).generate(3):\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the corresponding function and evaluate the perplexity of your model on the first 20 lines in the test data for values of `n` from 1 to 3. Perplexity should be individually calculated for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "Ngram model: 1\n",
      "perplexity 43.00983802910012\n",
      "********\n",
      "Ngram model: 2\n",
      "perplexity 20.523698868869687\n",
      "********\n",
      "Ngram model: 3\n",
      "perplexity 16.624383605963658\n"
     ]
    }
   ],
   "source": [
    "test_path = \"testing_files/berp-test.txt\"\n",
    "test_data = lm.read_file(test_path)\n",
    "for ngram in range(1, 4):\n",
    "    score = []\n",
    "    tokenized_train_data = lm.tokenize(test_data,ngram,by_char=False)\n",
    "    l= lm.LanguageModel(ngram)\n",
    "    l.train(tokenized_train_data)\n",
    "    for i in range(20):\n",
    "        sen = lm.tokenize_line(test_data[i],ngram,by_char=False)\n",
    "        #print(sen)\n",
    "        #print(l.perplexity(sen))\n",
    "        score.append(l.perplexity(sen))\n",
    "    print(\"********\")\n",
    "    print(\"Ngram model:\", ngram)\n",
    "    score =np.array(score)\n",
    "    print('perplexity',score.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
